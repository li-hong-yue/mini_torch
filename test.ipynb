{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing Conv2DTranspose: Mini-Torch vs PyTorch\n",
      "============================================================\n",
      "\n",
      "[Mini-Torch]\n",
      "Output shape: (2, 8, 3, 3)\n",
      "Output sample values:\n",
      "[[ 0.7351145  -0.24452999 -0.17586286]\n",
      " [ 0.3591942  -0.840743    0.11334914]\n",
      " [-0.26731247  0.19048168  0.24044836]]\n",
      "\n",
      "MSE Loss: 1.261473\n",
      "\n",
      "Gradients:\n",
      "  Input grad norm: 0.187378\n",
      "  Weight grad norm: 0.454128\n",
      "  Bias grad norm: 0.165461\n",
      "\n",
      "============================================================\n",
      "[PyTorch]\n",
      "Output shape: torch.Size([2, 8, 3, 3])\n",
      "Output sample values:\n",
      "[[ 0.7351145  -0.24452999 -0.17586286]\n",
      " [ 0.3591942  -0.840743    0.11334914]\n",
      " [-0.26731247  0.19048168  0.24044836]]\n",
      "\n",
      "MSE Loss: 1.261473\n",
      "\n",
      "Gradients:\n",
      "  Input grad norm: 0.187378\n",
      "  Weight grad norm: 0.454128\n",
      "  Bias grad norm: 0.165461\n",
      "\n",
      "============================================================\n",
      "[Comparison]\n",
      "============================================================\n",
      "\n",
      "Forward pass:\n",
      "  Max absolute difference: 1.19e-07\n",
      "  Mean absolute difference: 2.59e-09\n",
      "  ✓ PASS\n",
      "\n",
      "Input gradients:\n",
      "  Max absolute difference: 7.45e-09\n",
      "  Mean absolute difference: 4.83e-10\n",
      "  ✓ PASS\n",
      "\n",
      "Weight gradients:\n",
      "  Max absolute difference: 7.45e-09\n",
      "  Mean absolute difference: 6.75e-10\n",
      "  ✓ PASS\n",
      "\n",
      "Bias gradients:\n",
      "  Max absolute difference: 7.45e-09\n",
      "  Mean absolute difference: 2.21e-09\n",
      "  ✓ PASS\n",
      "\n",
      "============================================================\n",
      "Overall: ✓ ALL TESTS PASSED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mini_torch import Conv2DTranspose, Tensor, Linear, sigmoid, Module, Adam, Conv2D, relu, binary_cross_entropy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing Conv2DTranspose: Mini-Torch vs PyTorch\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Parameters\n",
    "    batch, in_c, H, W = 2, 3, 4, 4\n",
    "    out_c = 8\n",
    "    kernel_size = 3\n",
    "    stride = 2\n",
    "    padding = 3\n",
    "    \n",
    "    # Create input and target\n",
    "    input_data = np.random.randn(batch, in_c, H, W).astype(np.float32)\n",
    "    \n",
    "    # ============================================\n",
    "    # Mini-Torch\n",
    "    # ============================================\n",
    "    print(\"\\n[Mini-Torch]\")\n",
    "    \n",
    "    mini_conv_transpose = Conv2DTranspose(\n",
    "        in_channels=in_c, \n",
    "        out_channels=out_c, \n",
    "        kernel_size=kernel_size, \n",
    "        stride=stride,\n",
    "        padding=padding\n",
    "    )\n",
    "    \n",
    "    x_mini = Tensor(input_data)\n",
    "    out_mini = mini_conv_transpose(x_mini)\n",
    "    \n",
    "    print(f\"Output shape: {out_mini.shape}\")\n",
    "    print(f\"Output sample values:\\n{out_mini.data[0, 0]}\")\n",
    "    \n",
    "    # Compute loss and backward\n",
    "    target_mini = Tensor(np.random.randn(*out_mini.shape).astype(np.float32))\n",
    "    loss_mini = ((out_mini - target_mini).pow(2)).mean()\n",
    "    print(f\"\\nMSE Loss: {loss_mini.data.item():.6f}\")\n",
    "    \n",
    "    loss_mini.backward()\n",
    "    \n",
    "    print(f\"\\nGradients:\")\n",
    "    print(f\"  Input grad norm: {np.linalg.norm(x_mini.grad):.6f}\")\n",
    "    print(f\"  Weight grad norm: {np.linalg.norm(mini_conv_transpose.W.grad):.6f}\")\n",
    "    print(f\"  Bias grad norm: {np.linalg.norm(mini_conv_transpose.b.grad):.6f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # PyTorch\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"[PyTorch]\")\n",
    "    \n",
    "    pytorch_conv_transpose = nn.ConvTranspose2d(\n",
    "        in_channels=in_c,\n",
    "        out_channels=out_c,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        bias=True\n",
    "    )\n",
    "    \n",
    "    # Copy weights from mini-torch\n",
    "    with torch.no_grad():\n",
    "        # Note: PyTorch ConvTranspose2d weights are (in_channels, out_channels, kH, kW)\n",
    "        pytorch_conv_transpose.weight.copy_(torch.from_numpy(mini_conv_transpose.W.data))\n",
    "        pytorch_conv_transpose.bias.copy_(torch.from_numpy(mini_conv_transpose.b.data))\n",
    "    \n",
    "    x_torch = torch.from_numpy(input_data).requires_grad_(True)\n",
    "    out_torch = pytorch_conv_transpose(x_torch)\n",
    "    \n",
    "    print(f\"Output shape: {out_torch.shape}\")\n",
    "    print(f\"Output sample values:\\n{out_torch[0, 0].detach().numpy()}\")\n",
    "    \n",
    "    # Compute loss and backward\n",
    "    target_torch = torch.from_numpy(target_mini.data)\n",
    "    loss_torch = ((out_torch - target_torch) ** 2).mean()\n",
    "    print(f\"\\nMSE Loss: {loss_torch.item():.6f}\")\n",
    "    \n",
    "    loss_torch.backward()\n",
    "    \n",
    "    print(f\"\\nGradients:\")\n",
    "    print(f\"  Input grad norm: {torch.norm(x_torch.grad).item():.6f}\")\n",
    "    print(f\"  Weight grad norm: {torch.norm(pytorch_conv_transpose.weight.grad).item():.6f}\")\n",
    "    print(f\"  Bias grad norm: {torch.norm(pytorch_conv_transpose.bias.grad).item():.6f}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # Comparison\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"[Comparison]\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Compare outputs\n",
    "    output_diff = np.abs(out_mini.data - out_torch.detach().numpy())\n",
    "    print(f\"\\nForward pass:\")\n",
    "    print(f\"  Max absolute difference: {output_diff.max():.2e}\")\n",
    "    print(f\"  Mean absolute difference: {output_diff.mean():.2e}\")\n",
    "    print(f\"  ✓ PASS\" if output_diff.max() < 1e-5 else f\"  ✗ FAIL\")\n",
    "    \n",
    "    # Compare input gradients\n",
    "    input_grad_diff = np.abs(x_mini.grad - x_torch.grad.numpy())\n",
    "    print(f\"\\nInput gradients:\")\n",
    "    print(f\"  Max absolute difference: {input_grad_diff.max():.2e}\")\n",
    "    print(f\"  Mean absolute difference: {input_grad_diff.mean():.2e}\")\n",
    "    print(f\"  ✓ PASS\" if input_grad_diff.max() < 1e-5 else f\"  ✗ FAIL\")\n",
    "    \n",
    "    # Compare weight gradients\n",
    "    weight_grad_diff = np.abs(mini_conv_transpose.W.grad - pytorch_conv_transpose.weight.grad.numpy())\n",
    "    print(f\"\\nWeight gradients:\")\n",
    "    print(f\"  Max absolute difference: {weight_grad_diff.max():.2e}\")\n",
    "    print(f\"  Mean absolute difference: {weight_grad_diff.mean():.2e}\")\n",
    "    print(f\"  ✓ PASS\" if weight_grad_diff.max() < 1e-5 else f\"  ✗ FAIL\")\n",
    "    \n",
    "    # Compare bias gradients\n",
    "    bias_grad_diff = np.abs(mini_conv_transpose.b.grad - pytorch_conv_transpose.bias.grad.numpy())\n",
    "    print(f\"\\nBias gradients:\")\n",
    "    print(f\"  Max absolute difference: {bias_grad_diff.max():.2e}\")\n",
    "    print(f\"  Mean absolute difference: {bias_grad_diff.mean():.2e}\")\n",
    "    print(f\"  ✓ PASS\" if bias_grad_diff.max() < 1e-5 else f\"  ✗ FAIL\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    all_pass = (output_diff.max() < 1e-5 and \n",
    "                input_grad_diff.max() < 1e-5 and \n",
    "                weight_grad_diff.max() < 1e-5 and \n",
    "                bias_grad_diff.max() < 1e-5)\n",
    "    print(f\"Overall: {'✓ ALL TESTS PASSED' if all_pass else '✗ SOME TESTS FAILED'}\")\n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
